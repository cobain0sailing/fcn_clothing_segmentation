{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "sys.path.append(\"D:\\\\Git\\\\dpakhom1\\\\workspace\\\\models\\\\slim\")\n",
    "\n",
    "# A place where you have downloaded a network checkpoint -- look at the previous post\n",
    "checkpoints_dir = 'D:\\\\Git\\\\dpakhom1\\\\checkpoints'\n",
    "sys.path.insert(0,\"D:\\\\Git\\\\dpakhom1\\\\workspace\\\\models\\\\slim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "from numpy import ogrid, repeat, newaxis\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "# Generate image that will be used for test upsampling\n",
    "# Number of channels is 3 -- we also treat the number of\n",
    "# samples like the number of classes, because later on\n",
    "# that will be used to upsample predictions from the network\n",
    "imsize = 3\n",
    "x, y = ogrid[:imsize, :imsize]\n",
    "img = repeat((x + y)[..., newaxis], 3, 2) / float(imsize + imsize)\n",
    "#io.imshow(img, interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import skimage.transform\n",
    "\n",
    "def upsample_skimage(factor, input_img):\n",
    "\n",
    "    # Pad with 0 values, similar to how Tensorflow does it.\n",
    "    # Order=1 is bilinear upsampling\n",
    "    return skimage.transform.rescale(input_img,\n",
    "                                     factor,\n",
    "                                     mode='constant',\n",
    "                                     cval=0,\n",
    "                                     order=1)\n",
    "\n",
    "\n",
    "upsampled_img_skimage = upsample_skimage(factor=3, input_img=img)\n",
    "#io.imshow(upsampled_img_skimage, interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def get_kernel_size(factor):\n",
    "    \"\"\"\n",
    "    Find the kernel size given the desired factor of upsampling.\n",
    "    \"\"\"\n",
    "    return 2 * factor - factor % 2\n",
    "\n",
    "\n",
    "def upsample_filt(size):\n",
    "    \"\"\"\n",
    "    Make a 2D bilinear kernel suitable for upsampling of the given (h, w) size.\n",
    "    \"\"\"\n",
    "    factor = (size + 1) // 2\n",
    "    if size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:size, :size]\n",
    "    return (1 - abs(og[0] - center) / factor) * \\\n",
    "           (1 - abs(og[1] - center) / factor)\n",
    "\n",
    "\n",
    "def bilinear_upsample_weights(factor, number_of_classes):\n",
    "    \"\"\"\n",
    "    Create weights matrix for transposed convolution with bilinear filter\n",
    "    initialization.\n",
    "    \"\"\"\n",
    "\n",
    "    filter_size = get_kernel_size(factor)\n",
    "\n",
    "    weights = np.zeros((filter_size,\n",
    "                        filter_size,\n",
    "                        number_of_classes,\n",
    "                        number_of_classes), dtype=np.float32)\n",
    "\n",
    "    upsample_kernel = upsample_filt(filter_size)\n",
    "\n",
    "    for i in range(number_of_classes):\n",
    "\n",
    "        weights[:, :, i, i] = upsample_kernel\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "def upsample_tf(factor, input_img):\n",
    "\n",
    "    number_of_classes = input_img.shape[2]\n",
    "\n",
    "    new_height = input_img.shape[0] * factor\n",
    "    new_width = input_img.shape[1] * factor\n",
    "\n",
    "    expanded_img = np.expand_dims(input_img, axis=0)\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session() as sess:\n",
    "            with tf.device(\"/cpu:0\"):\n",
    "\n",
    "                upsample_filt_pl = tf.placeholder(tf.float32)\n",
    "                logits_pl = tf.placeholder(tf.float32)\n",
    "\n",
    "                upsample_filter_np = bilinear_upsample_weights(factor,\n",
    "                                        number_of_classes)\n",
    "\n",
    "                res = tf.nn.conv2d_transpose(logits_pl, upsample_filt_pl,\n",
    "                        output_shape=[1, new_height, new_width, number_of_classes],\n",
    "                        strides=[1, factor, factor, 1])\n",
    "\n",
    "                final_result = sess.run(res,\n",
    "                                feed_dict={upsample_filt_pl: upsample_filter_np,\n",
    "                                           logits_pl: expanded_img})\n",
    "\n",
    "    return final_result.squeeze()\n",
    "\n",
    "upsampled_img_tf = upsample_tf(factor=3, input_img=img)\n",
    "#io.imshow(upsampled_img_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Test if the results of upsampling are the same\n",
    "#np.allclose(upsampled_img_skimage, upsampled_img_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for factor in range(2, 10):\n",
    "\n",
    "    upsampled_img_skimage = upsample_skimage(factor=factor, input_img=img)\n",
    "    upsampled_img_tf = upsample_tf(factor=factor, input_img=img)\n",
    "\n",
    "    are_equal = np.allclose(upsampled_img_skimage, upsampled_img_tf)\n",
    "\n",
    "    #print(\"Check for factor {}: {}\".format(factor, are_equal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-9cea30bbd546>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# mean pixel value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;31m#mage_float = tf.to_float(image, name='ToFloat')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     \u001b[0mimage_float\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_float\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ToFloat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;31m# Subtract the mean pixel value from each pixel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import urllib.request\n",
    "\n",
    "from datasets import imagenet\n",
    "from nets import vgg\n",
    "from preprocessing import vgg_preprocessing\n",
    "\n",
    "checkpoints_dir = 'D:\\\\Git\\\\dpakhom1\\\\checkpoints'\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "# Load the mean pixel values and the function\n",
    "# that performs the subtraction\n",
    "from preprocessing.vgg_preprocessing import (_mean_image_subtraction,\n",
    "                                            _R_MEAN, _G_MEAN, _B_MEAN)\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "# Function to nicely print segmentation results with\n",
    "# colorbar showing class names\n",
    "def discrete_matshow(data, labels_names=[], title=\"\"):\n",
    "\n",
    "    fig_size = [7, 6]\n",
    "    plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "    #get discrete colormap\n",
    "    cmap = plt.get_cmap('Paired', np.max(data)-np.min(data)+1)\n",
    "\n",
    "    # set limits .5 outside true range\n",
    "    mat = plt.matshow(data,\n",
    "                      cmap=cmap,\n",
    "                      vmin = np.min(data)-.5,\n",
    "                      vmax = np.max(data)+.5)\n",
    "    #tell the colorbar to tick at integers\n",
    "    cax = plt.colorbar(mat,\n",
    "                       ticks=np.arange(np.min(data),np.max(data)+1))\n",
    "\n",
    "    # The names to be printed aside the colorbar\n",
    "    if labels_names:\n",
    "        cax.ax.set_yticklabels(labels_names)\n",
    "\n",
    "    if title:\n",
    "        plt.suptitle(title, fontsize=15, fontweight='bold')\n",
    "\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "\n",
    "   # url = (\"https://upload.wikimedia.org/wikipedia/commons/d/d9/\"\n",
    "   #        \"First_Student_IC_school_bus_202076.jpg\")\n",
    "    \n",
    "    url = (\"file:///C:/Users/ASUS/Pictures/m2015012812503378.jpg\")\n",
    "    image_string = urllib.request.urlopen(url).read()\n",
    "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
    "\n",
    "#    image_filename = \"cat.jpg\"\n",
    "    \n",
    "#    image_filename_placeholder = tf.placeholder(tf.string)\n",
    "#    feed_dict_to_use = {image_filename_placeholder: image_filename}\n",
    "#    image_tensor = tf.read_file(image_filename_placeholder)\n",
    "#    image_tensor = tf.image.decode_jpeg(image_tensor, channels=3)\n",
    "    \n",
    "    # Convert image to float32 before subtracting the\n",
    "    # mean pixel value\n",
    "    #mage_float = tf.to_float(image, name='ToFloat')\n",
    "    image_float = tf.to_float(image, name='ToFloat')\n",
    "\n",
    "    # Subtract the mean pixel value from each pixel\n",
    "    processed_image = _mean_image_subtraction(image_float,\n",
    "                                              [_R_MEAN, _G_MEAN, _B_MEAN])\n",
    "\n",
    "    input_image = tf.expand_dims(processed_image, 0)\n",
    "\n",
    "    with slim.arg_scope(vgg.vgg_arg_scope()):\n",
    "\n",
    "        # spatial_squeeze option enables to use network in a fully\n",
    "        # convolutional manner\n",
    "        logits, _ = vgg.vgg_16(input_image,\n",
    "                               num_classes=1000,\n",
    "                               is_training=False,\n",
    "                               spatial_squeeze=False)\n",
    "\n",
    "    # For each pixel we get predictions for each class\n",
    "    # out of 1000. We need to pick the one with the highest\n",
    "    # probability. To be more precise, these are not probabilities,\n",
    "    # because we didn't apply softmax. But if we pick a class\n",
    "    # with the highest value it will be equivalent to picking\n",
    "    # the highest value after applying softmax\n",
    "    pred = tf.argmax(logits, dimension=3)\n",
    "\n",
    "    init_fn = slim.assign_from_checkpoint_fn(\n",
    "        os.path.join(checkpoints_dir, 'vgg_16.ckpt'),\n",
    "        slim.get_model_variables('vgg_16'))\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        init_fn(sess)\n",
    "        segmentation, np_image, np_logits = sess.run([pred, image, logits])\n",
    "\n",
    "# Remove the first empty dimension\n",
    "segmentation = np.squeeze(segmentation)\n",
    "\n",
    "names = imagenet.create_readable_names_for_imagenet_labels()\n",
    "\n",
    "# Let's get unique predicted classes (from 0 to 1000) and\n",
    "# relable the original predictions so that classes are\n",
    "# numerated starting from zero\n",
    "unique_classes, relabeled_image = np.unique(segmentation,\n",
    "                                            return_inverse=True)\n",
    "\n",
    "segmentation_size = segmentation.shape\n",
    "\n",
    "relabeled_image = relabeled_image.reshape(segmentation_size)\n",
    "\n",
    "labels_names = []\n",
    "\n",
    "for index, current_class_number in enumerate(unique_classes):\n",
    "\n",
    "    labels_names.append(str(index) + ' ' + names[current_class_number+1])\n",
    "\n",
    "# Show the downloaded image\n",
    "plt.figure()\n",
    "plt.imshow(np_image.astype(np.uint8))\n",
    "plt.suptitle(\"Input Image\", fontsize=14, fontweight='bold')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "discrete_matshow(data=relabeled_image, labels_names=labels_names, title=\"Segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
